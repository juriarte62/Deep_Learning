{"cells":[{"cell_type":"markdown","source":["# Pretrained transformers\n","\n","Transformers can be pretrained on large amounts of unlabeled text by trying to predict the next word (as in GPT) or trying to predict missing words within a passage (as in BERT). This creates embeddings that are similar to word2vec, but incorporate the surrounding context, making them extremely powerful for all kinds of downstream Natural Language Processing tasks. In this tutorial, we will use a pretrained BERT model, with a classification head, to classify sentences as coming from different sections of structured abstracts."],"metadata":{"id":"X0vGnhH_dVbQ"},"id":"X0vGnhH_dVbQ"},{"cell_type":"markdown","id":"2ec0e8ff","metadata":{"id":"2ec0e8ff"},"source":["## Abstract section prediction with pretrained transformers\n","Scientific abstracts are often structured with labeled sections, like \"background\" and \"methods\" ([example](https://pubmed.ncbi.nlm.nih.gov/1429477/)). In this lab, we will try to predict which section a sentence came from. By leveraging embeddings from a pretrained model that already understands a lot about language, we will be able to solve this task with very few training examples and time.\n","\n","For more information see https://huggingface.co/docs/transformers/tasks/sequence_classification.\n"]},{"cell_type":"code","source":["!pip install datasets evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9pM8EKp_8S-I","executionInfo":{"status":"ok","timestamp":1745001595747,"user_tz":240,"elapsed":3224,"user":{"displayName":"Blindside","userId":"07630539884879584070"}},"outputId":"d7ea6021-8699-46f4-a4ff-de36d58e06cb"},"id":"9pM8EKp_8S-I","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]}]},{"cell_type":"code","execution_count":19,"id":"4343b6f7","metadata":{"scrolled":true,"id":"4343b6f7","executionInfo":{"status":"ok","timestamp":1745001595750,"user_tz":240,"elapsed":1,"user":{"displayName":"Blindside","userId":"07630539884879584070"}}},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from datasets import Dataset\n","import tensorflow as tf\n","import numpy as np\n","from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, AutoConfig # added AutoConfig -JU 4/18/2025\n","from transformers import create_optimizer\n","from transformers import DataCollatorWithPadding\n","from transformers.keras_callbacks import KerasMetricCallback\n","import evaluate\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","id":"ecd7538f","metadata":{"id":"ecd7538f"},"source":["This dataset has four possible labels:\n","\n","- 0: BACKGROUND\n","- 1: METHODS\n","- 2: RESULTS\n","- 3: CONCLUSIONS\n","\n","Load the data, split into training and validation, and create HuggingFace `Dataset` objects to help with tokenization and batching:"]},{"cell_type":"code","source":["!gdown 1kwdvVkYmsAFYdnppZPlFBDvVLQQtYgYC"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FknEXpWh9RCt","executionInfo":{"status":"ok","timestamp":1745001605796,"user_tz":240,"elapsed":10045,"user":{"displayName":"Blindside","userId":"07630539884879584070"}},"outputId":"de4ebb74-624f-488f-8b73-7329ed6ef711"},"id":"FknEXpWh9RCt","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1kwdvVkYmsAFYdnppZPlFBDvVLQQtYgYC\n","To: /content/data.tsv\n","100% 16.9M/16.9M [00:00<00:00, 69.5MB/s]\n"]}]},{"cell_type":"code","execution_count":21,"id":"f54e59de","metadata":{"id":"f54e59de","executionInfo":{"status":"ok","timestamp":1745001606561,"user_tz":240,"elapsed":739,"user":{"displayName":"Blindside","userId":"07630539884879584070"}}},"outputs":[],"source":["subset = 10000\n","\n","id2label = {0: \"BACKGROUND\", 1: \"METHODS\", 2: \"RESULTS\", 3: \"CONCLUSIONS\"}\n","label2id = {\"BACKGROUND\": 0, \"METHODS\": 1, \"RESULTS\": 2, \"CONCLUSIONS\": 3}\n","num_labels = 4\n","df = pd.read_csv('data.tsv', sep='\\t')\n","df = df[:subset]\n","df['label'] = [label2id[x] for x in df['label']]\n","df_train, df_val = train_test_split(df, test_size=0.1, random_state=0)\n","train_ds = Dataset.from_pandas(df_train, split=\"train\")\n","val_ds = Dataset.from_pandas(df_val, split=\"val\")"]},{"cell_type":"markdown","id":"916d4a2d","metadata":{"id":"916d4a2d"},"source":["Datasets have columns like DataFrames. Inspect the first few rows:"]},{"cell_type":"code","execution_count":22,"id":"bd6beb48","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bd6beb48","executionInfo":{"status":"ok","timestamp":1745001606561,"user_tz":240,"elapsed":2,"user":{"displayName":"Blindside","userId":"07630539884879584070"}},"outputId":"7cd83a46-f165-4ebe-d4ce-6fcf9fa95e10"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'label': [2, 2, 3, 3, 1],\n"," 'text': ['Drug sequence had no effect on toxicities. ',\n","  'Four adult patients had transient hypotension. ',\n","  'Rimexolone has a low IOP-elevating potential, comparable to that of fluorometholone and less than that of dexamethasone sodium phosphate and prednisolone acetate.',\n","  'We believe that this is only the second reported case of acute cholestatic jaundice resulting from ciprofloxacin therapy. ',\n","  'In a Phase II trial, the authors evaluated the influence of paclitaxel, carboplatin, and an antimotility factor (acellular pertussis vaccine [APV]) in 18 patients with cisplatin- and methotrexate-resistant metastatic bladder carcinoma. '],\n"," '__index_level_0__': [1554, 2087, 5470, 2363, 7570]}"]},"metadata":{},"execution_count":22}],"source":["train_ds[0:5]"]},{"cell_type":"markdown","id":"f9180e27","metadata":{"id":"f9180e27"},"source":["Load the pretrained transformer model from [HuggingFace](https://huggingface.co), an extremely popular library and repository for loading and manipulating language models. In this case we will be using [DistilBERT](https://arxiv.org/pdf/1910.01108.pdf%3C/p%3E), a smaller (and faster) verison of the seminal [BERT](https://arxiv.org/pdf/1810.04805.pdf&usg=ALkJrhhzxlCL6yTht2BRmH9atgvKFxHsxQ) pretrained transformer model. Also note that this is a \"...ForSequenceClassification\" model, which means it already has a randomly initialized feedforward head on top of the transformer embedding model, ready for us to train."]},{"cell_type":"markdown","source":["**1. Initialize an [`AutoTokenizer`](https://huggingface.co/docs/transformers/v4.35.2/en/model_doc/auto) named `tokenizer` using `distilbert-base-uncased` as the pretrained model path and using truncation.**"],"metadata":{"id":"WbPbyQysd3VI"},"id":"WbPbyQysd3VI"},{"cell_type":"code","source":["# YOUR CODE HERE (1)\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", use_fast=True)"],"metadata":{"id":"oxWKM__Vd18p","executionInfo":{"status":"ok","timestamp":1745001606990,"user_tz":240,"elapsed":429,"user":{"displayName":"Blindside","userId":"07630539884879584070"}}},"id":"oxWKM__Vd18p","execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["**2. Initialize a [`TFAutoModelForSequenceClassification`](https://huggingface.co/docs/transformers/v4.35.2/en/model_doc/auto#transformers.TFAutoModelForSequenceClassification) named `model`, again using `distilbert-base-uncased` as the pretrained model path.**\n","- Hint: You will need to specify `num_labels` and the dictionaries `id2label` and `label2id`. See the definitions of these above."],"metadata":{"id":"ZBxGib5gd2e0"},"id":"ZBxGib5gd2e0"},{"cell_type":"code","execution_count":24,"id":"ecce5253","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecce5253","executionInfo":{"status":"ok","timestamp":1745001608613,"user_tz":240,"elapsed":1624,"user":{"displayName":"Blindside","userId":"07630539884879584070"}},"outputId":"e363009e-5354-4365-8d4d-1becb682ec5d"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# YOUR CODE HERE (2)\n","config = AutoConfig.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels, id2label=id2label, label2id=label2id)\n","model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", config=config)"]},{"cell_type":"markdown","id":"8779c646","metadata":{"id":"8779c646"},"source":["It has warned us that the weights of the pretrained model don't all match the classification model. That makes sense, because we are taking of the old top (which predicted missing words) and putting on our new one (which predicts a class). The warning thus advises us to train this new model, and that's exactly what we will do!\n","\n"]},{"cell_type":"markdown","source":["### Tokenization\n","\n","Text data needs to be \"tokenized,\" which is the process of coverting raw strings into sequences of numbers that identify 'tokens' in our vocabulary. Tokens can be whole words, but some are punctuation or pieces of words. Having pieces of words in the vocabulary lets us handle words that were not in the pretraining data."],"metadata":{"id":"GXofX1y2TQE9"},"id":"GXofX1y2TQE9"},{"cell_type":"code","execution_count":25,"id":"e6ee9422","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["b8a2705fab9c43459920470e14909862","e576457f2b854beabf678ab4fe73deb3","9b3f505f83884f27969c39117f73b131","e68f35b0f7924232a3f64dbab2afda15","933d1b473aef406180539fe97824882d","8c73526a088a47e48e5ffae95ac56954","9fa963c9571f4d3e9aa4165c028e2f29","398c3db98cf247b3a1193fdc671db89d","e8123a84bb4a4629857c59de8f16c278","d61fdc3fa0114594be30bde6d1523d03","77de07c8a63a41549b47c0e998ae3b5d","42bccda7aa2a43b2ae05537c0a132f31","df5f851b619d4f54bce64e9e9c271786","18b16cde6c684428a3157c5d3cdead69","8cbcdd2d5ebb4754be311f83088c2534","f80d2be91b9044ff9b86a677945662dd","0f09f302b9da4f5f90e90e4ef25d8a75","fa14754241cf4e2582215bddfc1615f7","b0b5505d913045af8bd57b10849830d8","5d42f401e5124679885856cfc17b0543","a262de473dc4402c9b268432e369ba15","03ce3b55b8dd45e297284b6444a5857c"]},"id":"e6ee9422","executionInfo":{"status":"ok","timestamp":1745001611302,"user_tz":240,"elapsed":2692,"user":{"displayName":"Blindside","userId":"07630539884879584070"}},"outputId":"085c0db3-8a0a-4f8a-9f85-7e3b6aaeed88"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/9000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8a2705fab9c43459920470e14909862"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42bccda7aa2a43b2ae05537c0a132f31"}},"metadata":{}}],"source":["data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n","\n","def preprocess_function(examples):\n","    return tokenizer(examples[\"text\"], truncation=True)\n","\n","tokenized_train = train_ds.map(preprocess_function, batched=True)\n","tokenized_val = val_ds.map(preprocess_function, batched=True)\n","\n","tf_train_set = model.prepare_tf_dataset(\n","    tokenized_train,\n","    shuffle=True,\n","    batch_size=16,\n","    collate_fn=data_collator,\n",")\n","\n","tf_validation_set = model.prepare_tf_dataset(\n","    tokenized_val,\n","    shuffle=False,\n","    batch_size=16,\n","    collate_fn=data_collator,\n",")"]},{"cell_type":"markdown","id":"22712a53","metadata":{"id":"22712a53"},"source":["After tokenizing, our dataset has the additional fields `input_ids` (the list of tokens in each sentence) and `attention_mask` (which allows padding sentences to the same length):"]},{"cell_type":"code","execution_count":26,"id":"c9978ab1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9978ab1","executionInfo":{"status":"ok","timestamp":1745001611318,"user_tz":240,"elapsed":9,"user":{"displayName":"Blindside","userId":"07630539884879584070"}},"outputId":"595fb0b1-9cb8-4d9e-8934-cecbcc7b1969"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'label': 2,\n"," 'text': 'Drug sequence had no effect on toxicities. ',\n"," '__index_level_0__': 1554,\n"," 'input_ids': [101,\n","  4319,\n","  5537,\n","  2018,\n","  2053,\n","  3466,\n","  2006,\n","  11704,\n","  6447,\n","  1012,\n","  102],\n"," 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":26}],"source":["tokenized_train[0]"]},{"cell_type":"markdown","id":"4c0f940b","metadata":{"id":"4c0f940b"},"source":["Set up the training process, including compiling the model, computing steps, and setting up a callback to evaluate accuracy on the validation set after each epoch."]},{"cell_type":"code","execution_count":27,"id":"2209d5b4","metadata":{"id":"2209d5b4","executionInfo":{"status":"ok","timestamp":1745001614238,"user_tz":240,"elapsed":2918,"user":{"displayName":"Blindside","userId":"07630539884879584070"}}},"outputs":[],"source":["batch_size = 16\n","num_epochs=1\n","batches_per_epoch = len(tokenized_train) // batch_size\n","total_train_steps = int(batches_per_epoch * num_epochs)\n","optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)\n","accuracy = evaluate.load(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    return accuracy.compute(predictions=predictions, references=labels)\n","\n","metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)"]},{"cell_type":"markdown","source":["**3. Compile the model, using the optimizer defined by `create_optimizer` above.**\n","- Hint: HuggingFace will take care of loss, so it should not be specified."],"metadata":{"id":"rDcmm2Wum09o"},"id":"rDcmm2Wum09o"},{"cell_type":"code","source":["# YOUR CODE HERE (3)\n","model.compile(optimizer=optimizer)"],"metadata":{"id":"d3f85410","executionInfo":{"status":"ok","timestamp":1745001614257,"user_tz":240,"elapsed":17,"user":{"displayName":"Blindside","userId":"07630539884879584070"}}},"id":"d3f85410","execution_count":28,"outputs":[]},{"cell_type":"markdown","id":"b8c83667","metadata":{"id":"b8c83667"},"source":["Now we just need to run fit (this will take a few minutes).\n","\n","**4. Fit the model on the training set for 1 epoch, validating on the validation set and using `metric_callback` as the only callback.**"]},{"cell_type":"code","execution_count":29,"id":"0a79aae0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0a79aae0","executionInfo":{"status":"ok","timestamp":1745001775012,"user_tz":240,"elapsed":160754,"user":{"displayName":"Blindside","userId":"07630539884879584070"}},"outputId":"18f4eb02-67c9-4545-dcc6-786e93d5ac05"},"outputs":[{"output_type":"stream","name":"stdout","text":["562/562 [==============================] - 127s 182ms/step - loss: 0.5632 - val_loss: 0.4639 - accuracy: 0.8440\n"]},{"output_type":"execute_result","data":{"text/plain":["<tf_keras.src.callbacks.History at 0x7b56759bc150>"]},"metadata":{},"execution_count":29}],"source":["# YOUR CODE HERE (4)\n","model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=1, callbacks=[metric_callback])"]},{"cell_type":"markdown","id":"12de640d","metadata":{"id":"12de640d"},"source":["This accuracy is not bad for a single epoch of a few thousand training examples, and for a 4-class classification problem! See how high you can get the accuracy with more epochs and more of the available data (see `subset` above).\n","\n","To use our model, we need to define an inference function:"]},{"cell_type":"code","execution_count":30,"id":"4db3c856","metadata":{"id":"4db3c856","executionInfo":{"status":"ok","timestamp":1745001775013,"user_tz":240,"elapsed":2,"user":{"displayName":"Blindside","userId":"07630539884879584070"}}},"outputs":[],"source":["def classify(text):\n","    inputs = tokenizer(text, return_tensors=\"tf\")\n","    logits = model(**inputs).logits\n","    predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])\n","    return model.config.id2label[predicted_class_id]"]},{"cell_type":"markdown","id":"9f9f3f3d","metadata":{"id":"9f9f3f3d"},"source":["Let's see what the model says about a few sentences (try your own!):"]},{"cell_type":"code","execution_count":31,"id":"3b9abe29","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"3b9abe29","executionInfo":{"status":"ok","timestamp":1745001775129,"user_tz":240,"elapsed":117,"user":{"displayName":"Blindside","userId":"07630539884879584070"}},"outputId":"73e9d4a4-267c-4d37-dd73-bc50080386b9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'BACKGROUND'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":31}],"source":["classify(\"\"\"Little work has been done in humans to evaluate\n","the potential benefit of potassium supplementation.\"\"\")"]},{"cell_type":"code","execution_count":32,"id":"4f3caa68","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"4f3caa68","executionInfo":{"status":"ok","timestamp":1745001775323,"user_tz":240,"elapsed":194,"user":{"displayName":"Blindside","userId":"07630539884879584070"}},"outputId":"ee1ab6a4-961d-4155-a509-f7d4cf86c854"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'RESULTS'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":32}],"source":["classify(\"\"\"The mean MDS-UPDRS total score at baseline was 34.3 in\n","the deferiprone group and 33.2 in the placebo group and increased\n","(worsened) by 15.6 points and 6.3 points, respectively (difference,\n","9.3 points; 95% confidence interval, 6.3 to 12.2; P<0.001).\"\"\")"]},{"cell_type":"code","execution_count":33,"id":"8f90b538","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"8f90b538","executionInfo":{"status":"ok","timestamp":1745001775390,"user_tz":240,"elapsed":68,"user":{"displayName":"Blindside","userId":"07630539884879584070"}},"outputId":"b477e930-a139-496e-e05f-b2d7d602a7ec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'METHODS'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}],"source":["classify(\"\"\"We conducted a multicenter, phase 2, randomized, double-blind\n","trial involving participants with newly diagnosed Parkinson's disease who\n","had never received levodopa.\"\"\")"]},{"cell_type":"code","source":[],"metadata":{"id":"XenFYKzLn0lS","executionInfo":{"status":"ok","timestamp":1745001775392,"user_tz":240,"elapsed":2,"user":{"displayName":"Blindside","userId":"07630539884879584070"}}},"id":"XenFYKzLn0lS","execution_count":33,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b8a2705fab9c43459920470e14909862":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e576457f2b854beabf678ab4fe73deb3","IPY_MODEL_9b3f505f83884f27969c39117f73b131","IPY_MODEL_e68f35b0f7924232a3f64dbab2afda15"],"layout":"IPY_MODEL_933d1b473aef406180539fe97824882d"}},"e576457f2b854beabf678ab4fe73deb3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c73526a088a47e48e5ffae95ac56954","placeholder":"​","style":"IPY_MODEL_9fa963c9571f4d3e9aa4165c028e2f29","value":"Map: 100%"}},"9b3f505f83884f27969c39117f73b131":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_398c3db98cf247b3a1193fdc671db89d","max":9000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8123a84bb4a4629857c59de8f16c278","value":9000}},"e68f35b0f7924232a3f64dbab2afda15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d61fdc3fa0114594be30bde6d1523d03","placeholder":"​","style":"IPY_MODEL_77de07c8a63a41549b47c0e998ae3b5d","value":" 9000/9000 [00:02&lt;00:00, 4034.33 examples/s]"}},"933d1b473aef406180539fe97824882d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c73526a088a47e48e5ffae95ac56954":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fa963c9571f4d3e9aa4165c028e2f29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"398c3db98cf247b3a1193fdc671db89d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8123a84bb4a4629857c59de8f16c278":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d61fdc3fa0114594be30bde6d1523d03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77de07c8a63a41549b47c0e998ae3b5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42bccda7aa2a43b2ae05537c0a132f31":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df5f851b619d4f54bce64e9e9c271786","IPY_MODEL_18b16cde6c684428a3157c5d3cdead69","IPY_MODEL_8cbcdd2d5ebb4754be311f83088c2534"],"layout":"IPY_MODEL_f80d2be91b9044ff9b86a677945662dd"}},"df5f851b619d4f54bce64e9e9c271786":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f09f302b9da4f5f90e90e4ef25d8a75","placeholder":"​","style":"IPY_MODEL_fa14754241cf4e2582215bddfc1615f7","value":"Map: 100%"}},"18b16cde6c684428a3157c5d3cdead69":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0b5505d913045af8bd57b10849830d8","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d42f401e5124679885856cfc17b0543","value":1000}},"8cbcdd2d5ebb4754be311f83088c2534":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a262de473dc4402c9b268432e369ba15","placeholder":"​","style":"IPY_MODEL_03ce3b55b8dd45e297284b6444a5857c","value":" 1000/1000 [00:00&lt;00:00, 4194.86 examples/s]"}},"f80d2be91b9044ff9b86a677945662dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f09f302b9da4f5f90e90e4ef25d8a75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa14754241cf4e2582215bddfc1615f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0b5505d913045af8bd57b10849830d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d42f401e5124679885856cfc17b0543":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a262de473dc4402c9b268432e369ba15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03ce3b55b8dd45e297284b6444a5857c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}